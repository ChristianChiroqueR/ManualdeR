[["index.html", "Manual de R Studio para ciencias sociales Presentación 0.1 Sobre el autor 0.2 Sugerencia de citado", " Manual de R Studio para ciencias sociales Christian Chiroque 2021-04-10 Presentación Este libro tiene como objetivo ser un soporte para el aprendizaje del software R, a través del IDE R Studio, y está especialmente dirigido para aquellos estudiantes de ciencias sociales, en general, y ciencia política, en particular. Lo más resaltante de este manual: Presenta de una manera fácil, ordenada y práctica los principales temas en estadística aplicada Incorpora material audiovisual al proceso de aprendizaje de estadística en ciencias sociales (videos del canal de Youtube Data Política, creado por el autor de este manual) No pretende ser un libro teórico, sino una práctico. Se hará referencia a la teoría en la medida que ayude a tener una idea más clara de lo que se está trabajando en el programa, sin embargo, no es su finalidad principal. El presente manual fue una iniciativa personal en el marco de mi labor docente en la Facultad de Ciencias Sociales de la Pontificia Universidad Católica del Perú (cursos Estadística para el Análisis Política 1 y 2). Para la construcción de este libro se utilizaron 1) los paquetes de Bookdown y RMarkdown de R Studio; 2) y el programa Git y la plataforma Github para el control de versiones y Github Pages. 0.1 Sobre el autor Christian Chiroque Ruiz. Politólogo con maestría en Gerencia Social por la Pontificia Universidad Católica del Perú PUCP y especialista en Estadística Aplicada por la Escuela Nacional de Estadística e Informática ENEI. Estudiante de la Maestría de Estadística Aplicada de la Universidad Nacional Agraria La Molina. Se desempeña como especialista en gestión social para proyectos de inversión y es docente en la Facultad de Ciencias Sociales de la PUCP. Es creador de Data Política (canal de youtube para la difusión de estadística aplicada) y cofundador de Leyendo el Poder (grupo de debate de teorías de ciencia política y estudios internacionales). 0.2 Sugerencia de citado Chiroque, Christian (2020) Manual de R Studio para ciencias sociales. Data Política: Lima "],["r-un-software-libre.html", "Capítulo 1 R, un software libre 1.1 Aspectos básicos 1.2 Guía de instalación", " Capítulo 1 R, un software libre En esta primera parte vamos a aprender los principales elementos para entender el funcionamiento del R y del R Studio. 1.1 Aspectos básicos En este video vamos a comentar las principales características del R y qué diferencias podemos identificar con otros paquetes estadísticos como el SPSS. Así también, veremos cómo es el procedimiento para la instalación del R y del R Studio. En resumen podríamos hacer una comparación entre el R y el SPSS para ver sus principales característicass. Image 1.2 Guía de instalación Como hemos comentado, primero debemos instalar el R (el software estadístico), el cual lo podemos descargar en el siguiente enlace: https://cran.r-project.org/bin/windows/base/ Posteriormente, debemos descargar el R Studio. RStudio es una interfaz, un entorno de desarrollo integrado (IDE) para el lenguaje de programación R, dedicado a la computación estadística y gráficos. Incluye una consola, editor de sintaxis que apoya la ejecución de código, así como herramientas para el trazado, la depuración y la gestión del espacio de trabajo. En otras palabras, es una interfaz que nos facilita la utilización del R y que viene con una serie de elementos para agilizar la programación. Se puede descargar en el siguiente enlace (seleccionar opción Open Source Licence): https://rstudio.com/products/rstudio/download/ El orden es importante. Primero se debe instalar el R y luego el R Studio. "],["r-un-lenguaje-de-programación.html", "Capítulo 2 R, un lenguaje de programación 2.1 Entorno de programación 2.2 Código en R 2.3 Clases de objetos en R", " Capítulo 2 R, un lenguaje de programación 2.1 Entorno de programación Vamos a comprender por qué es necesario saber un lenguaje de programación para aprender estadística en la ciencias sociales, así como cuál es la lógica que está detrás de las líneas de código. Te sugiero ver el siguiente video: Para iniciar el uso del R Studio debemos conocer cuáles son sus principales partes (o paneles clave) y cuál es la función de cada una de estas. Dentro de los elementos claves que debemos identificar en el R Studio se encuentran los siguientes: Principales partes del R Studio 2.1.1 Consola Siguiendo nuestra analogía, lo podemos recordar como nuestra mesa de trabajo. La consola viene a ser la parte principal de la interfaz. Es la zona donde ingresamos el código y también donde aparecen los resultados de las órdenes que le damos al programa. De esta manera, cuando solicitemos, por ejemplo, la media de una variable el resultado nos aparecerá en la consola. Identificando las partes básicas 2.1.2 Manuales del programador Los manuales de instrucciones son archivos de texto en los cuales podemos escribir todos los códigos que deseemos aplicar a un conjunto de objetos. La ventaja clave de este tipo de manuales radica en que es un archivo que podemos guardar (con extensión .R) para poder ejecutar los códigos en otro momento. Así también, sirven para que nosotros podamos compartir los procedimientos que hemos seguido para desarrollar una investigación con el fin de que puedan ser replicados (o ejecutados) por otros investigadores. Cuando abrimos un manual nos aparece en el cuadrante superior izquierdo de nuestra interfaz del R Studio. Los más conocidos son: Script, R Markdown y R Notebook. 2.1.3 Paquetes Ya tenemos la mesa de trabajo (consola) y el manual (script), ahora necesitamos ubicar las cajas de herramientas según lo que deseamos hacer. Los paquetes (también llamados bibliotecas) son colecciones de funciones, generalmente agrupadas para una tarea específico. Podríamos seguir con la analogía, imaginemos que tenemos una caja de herramientas para trabajos eléctricos, otra para carpintería, etc. En el caso del análisis estadístico, podemos tener un paquete que contiene funciones para análisis exploratorio de datos, análisis geoespacial, bioestadística, modelamiento de datos, deeplearning, entre otros temas. Cuando nosotros instalamos el R Studio este viene con un conjunto de paquete preinstalados. Esto quiere decir que ya tenemos un grupo de funciones (las más comunes) que podemos solicitar directamente. Sin embargo, a medida que avancemos en el uso del R, nos vamos a dar cuenta que esos paquetes preinstalados no van a ser suficientes. Una vez que sabemos qué queremos hacer, debemos instalar los paquetes más adecuados. Para ello, utilizamos la siguiente función: install.packages(&quot;nombre_del_paquete&quot;) Luego de solicitar la instalación nos aparecerán algunos mensajes en la consola y tenemos que asegurarnos que diga que el paquete se ha instalado exitosamente. 2.1.4 Funciones El paso siguiente, una vez ubicada nuestra consola (mesa de trabajo), nuestro script (manual de instrucciones) y el paquete a utilizar (caja de herramientas) , debemos seleccionar la función que necesitemos (la herramienta más idónea). Una función es un conjunto de operaciones sistematizadas que el programa ejecuta sobre ciertos argumentos u objetos. Para utilizar una función es necesario primero abrir un paquete (al igual que si queremos una herramienta necesitamos abrir primero la caja de herramientas donde se encuentra). Para realizar dicha tarea debemos usar la siguiente función: library(nombre_del_paquete) Esta función lo que hace es abrir el paquete que ya está instalado y dejar a disposición del usuario todas las funciones que se encuentran en el mismo. Luego de ello, ya podemos solicitar la función. Por ejemplo, si queremos realizar un histograma de la variable ingresos debemos escribir: hist(ingresos) En la línea de comando anterior hist es el nombre de la función que se aplica sobre la variable ingresos. Es importante mencionar que en el R el usuario también puede crear sus propias funciones para, por ejemplo, solicitar un conjunto de acciones al programa de forma fácil y con un simple comando. Sin embargo, este punto será desarrollado más adelante. 2.1.5 Objetos El R es un lenguaje de programación que está orientado a objetos. Esto quiere decir que el programa utiliza las funciones, anteriormente explicadas, sobre elementos que guarda en la memoria activa del computador con un nombre específico. De esta manera, el usuario del programa puede manipular, alterar, modificar estos objetos utilizando operadores o funciones. Podemos ver estos objetos como la madera sobre la cual vamos a aplicar las herramientas que ya tenemos a la mano. En nuestro caso el objeto más usual que utilizaremos será los de tipo data.frame o también conocidas como bases de datos. A partir de los cuales podemos seleccionar otros objetos como variables y, a su vez, crear nuevos objetos como tablas, gráficos, modelos, entre otros. Todos los objetos que tenemos disponibles en nuestra sesión de R Studio aparecen en nuestra sección de Environment, en el cuadrante superior derecho. Si no aparece ningún objeto eso quiere decir que tenemos que crearlos o, en todo caso, cargarlos al programa. 2.2 Código en R Te recomiendo ver el siguiente tutorial: 2.2.1 Script Ya habíamos comentado en la sección anterior que el Script es una parte muy importante de la interfaz del R Studio y que nos va a ayudar mucho durante nuestro trabajo. El Script, el cual es un archivo con extensión .R, es un documento de texto que tiene la peculiaridad que puede ser leídos por el programa como un manual de código. De esa forma, nosotros podemos colocar en el script los códigos de nuestro análisis, ordenarlos, comentarlos y reproducirlos en el R Studio automáticamente. En suma, podemos redactar nuestros script, compartirlos con otros investigadores y ejecutarlos. Cuando abrimos un Script en el R Studio nos aparece una ventana en la parte superior izquierda de nuestra interfaz. Ahí nosotros podemos comenzar a redactar, como cualquier documento de texto, nuestros códigos. Sin embargo, nosotros podemos agregar información en el Script de dos formas específicas: Como comentario: Cuando nosotros colocamos el símbolo # al iniciar una oración, el Script lo va a identificar como un comentario del programador, como un texto que no va a ser ejecutado como código. Esto es importante porque nos permite ir comentando, por ejemplo, lo que estamos redactando en el documento. Ej: Este código sirve para abrir un archivo, Aquí estoy haciendo un análisis de regresión, entre otros. Como código: Cuando escribimos directamente en el documento el programa lo va a entender como código o funciones. Esto es importante tenerlo en cuenta para evitar notificaciones de Error. En resumen: para agregar un comentario ponemos antes el símbolo # y para agregar una función escribimos directamente. 2.2.2 R Markdown El R Markdown es una sintaxis de formato simple que nos permite elaborar informes de manera rápida y sencilla. Los principales tipos de documentos que podemos elaborar con esta sintaxis son PDF, HTML (para verlo desde un navegador web), Word, entre muchos más. Algunas pecualiaridades del documento: Incluir texto: A diferencia del script (en el cual teníamos que decirle al programa qué líneas son comentarios), en el R Markdown podemos redactar directamente sin ningún problema. El R Studio lo va a detectar como texto que forma parte del informe. Incluir códigos: Ahora bien, para incluir código debemos crear los denominados chunks. Estos son trozos de código que vamos a agregar a lo largo del texto y que tendrán la particularidad de que serán ejecutados por el programa cuando produzcamos el informe. Por ejemplo, si en nuestro informe queremos incluir el gráfico de la base cars debemos redactar lo siguiente: plot(cars) Para facilitarnos las cosas, el programa nos da una opción, que se encuentra en la parte superior derecha del documento Markdown, que dice Insert. Cuando queramos agregar un código de R, simplemente damos click al botón y elegimos R. Una vez terminemos nuestro informe podemos visualizarlo dando click en el botón Knit. Nos daremos cuenta que el programa abrirá un documento HTML (si eso hemos elegido) en una ventana diferente. Una particularidad de los R Markdown es que al momento de presionar Knit, este corre TODOS los códigos del documento. En general, una forma de verlo es la siguiente: si el Script era un documento de códigos en el cual podíamos agregar textos (usando el #), el R Markdown es un documento/informe de texto en el cual podemos agregar códigos (con los chunks). 2.2.3 R Notebook El R Notebook es una variante del R Markdown que se ha introducido recientemente al programa. Tiene las mismas características de un R Markdown en relación al ingreso de información: el texto se ingresa directamente y se tienen que colocar chunks para ingresas trozos de código. Sin embargo, tiene algunas diferencias que lo hacen peculiarmente interesante a diferencia del R Markdown: Lo primero es que nos permite ejecutar los códigos dentro del mismo documento. Para ello, simplemente ponemos el botón de Run que se encuentra en la parte superior derecha (como si fuera un script). Cuando guardamos el R Notebook automáticamente se crea un archivo HTML (en nuestro directorio de trabajo) que contiene el código. Sin embargo, incluirá sólo las salidas (outputs) que han sido ejecutadas (Run) en el documento. Nos permite visualizar una Vista Previa con el botón Preview. Podemos seleccionar verla en una ventana aparte o dentro del panel visualizador (Viewer) dentro de la interfaz del R Studio. 2.3 Clases de objetos en R El R es un lenguaje de programación orientado a objetos, por ello, es necesario saber con qué clases de objetos podemos encontrarnos. Los objetos más básicos en R son los siguientes: character: Ej: rojo. numeric: Ej: 1.5 integer: Números enteros. Ej: 1L logical: Ej: TRUE o FALSE complex: Números complejos. Ej: 1+2i Ahora bien, uno puede crear distintas estructuras, las cuales se pueden formar combinando estos elementos básicos. Por ejemplo, la estructura más conocida es el vector, el cual es un conjunto de objetos de la misma clase (como si fuese una fila de objetos): sólo caracteres, sólo numéricos, sólo lógicos, etc. Image Para los fines de este libro se contemplarán las siguientes estructuras de datos: Tipo de vector Descripción Vector de factores Vector que sirve para representar variables categóricas. Pudiendo ser factores nominales u ordinales. Ej: costa, sierra, selva Vectores numéricos Vector conformado por la concatenación de números. Ej: 1.5 , 2.7 , 3.1 Matrices Son hojas de datos homogéneos, es decir, de un sólo tipo. Tiene columnas y filas Data frames Son hojas de datos, estructuras similares a una matriz; sin embargo, a diferencia de estas pueden almacenar objetos de distintos tipo. Generalmente nuestras bases de datos son de este tipo (como una hoja de Excel que tiene variables numéricas, categóricas, etc). Listas Conjunto de objetos de distinta clase. Ej: rojo, 1, lápiz. Algunas veces las vamos a utilizar a la hora de hacer nuestros cálculos. Tener en cuenta. Recuerda: la clase de un objeto determinará de qué modo será tratado por el programa. El programa está dirigido a objetos y las funciones que están dentro de él también. 2.3.1 Identificando el tipo de objeto Nosotros podemos identificar la clase de objetos que tenemos mediante la función class(): Creamos un vector numérico: x= c(1, 2, 3) x ## [1] 1 2 3 class(x) ## [1] &quot;numeric&quot; Creamos un vector character: y=c(&quot;gato&quot;, &quot;perro&quot;, &quot;loro&quot;) y ## [1] &quot;gato&quot; &quot;perro&quot; &quot;loro&quot; class(y) ## [1] &quot;character&quot; Solicitamos que nos muestre el tipo de objeto que es nuestra base de datos de trabajadores: head(trabajadores) ## id sexo fechnac educ catlab salario_actual salario_inicial antiguedad ## 1 1 1 1952-02-03 15 3 57000 27000 98 ## 2 2 1 1958-05-23 16 1 40200 18750 98 ## 3 3 0 1929-07-26 12 1 21450 12000 98 ## 4 4 0 1947-04-15 8 1 21900 13200 98 ## 5 5 1 1955-02-09 15 1 45000 21000 98 ## 6 6 1 1958-08-22 15 1 32100 13500 98 ## experiencia minoría directivo ## 1 144 0 1 ## 2 36 0 0 ## 3 381 0 0 ## 4 190 0 0 ## 5 138 0 0 ## 6 67 0 0 class(trabajadores) ## [1] &quot;data.frame&quot; De esta manera, le hemos preguntado al programa qué tipo de objeto es trabajadores y nos ha respondido que es un data.frame. 2.3.2 Características de los objetos Cada objeto tiene un conjunto de características particulares. Por ejemplo, como ya tenemos nuestra base de datos cargada (trabajadores), podemos aplicar un conjunto de funciones para profundizar en sus características. Hay muchas formas de conocer la estructura de esta data, sin embargo, sugiero seguir siempre los siguientes pasos: Número de columnas y filas tiene nuestra base de datos Utilizamos la función dim para ver las dimensiones del archivo: dim(ejemplo) ## [1] 474 11 El primer número indica las filas (o número de casos) y el segundo el número de columnas (o variables). Contenido de la base de datos Para ello utilizamos la función names y entre paréntesis ponemos el nombre de nuestra data: names(trabajadores) ## [1] &quot;id&quot; &quot;sexo&quot; &quot;fechnac&quot; &quot;educ&quot; ## [5] &quot;catlab&quot; &quot;salario_actual&quot; &quot;salario_inicial&quot; &quot;antiguedad&quot; ## [9] &quot;experiencia&quot; &quot;minoría&quot; &quot;directivo&quot; De esta manera, nos damos cuenta que la base de datos trabajadores tiene 11 variables. 2.3.3 Acceder a las partes de un objeto Como hemos mencionado líneas arriba, hay ocasiones en que un objeto está compuesto por varios elementos a los cuales nosotros también podemos tener acceso. Creemos el siguiente objeto: x= c(4, 7, 9) x ## [1] 4 7 9 Ahora solicitemos sólo un elemento de este vector. Ej: solicitemos el segundo componente, para ello hacemos uso de los corchetes [] x[2] ## [1] 7 Otra forma de acceder a una parte de un objeto es haciendo uso del símbolo $. Esto va a ser muy útil cuando nos refiramos a, por ejemplo, una variable en específico dentro de una base datos. Por ejemplo, el siguiente código solicita la clase del objeto trabajadores, que es nuestra base de datos: class(trabajadores) ## [1] &quot;data.frame&quot; Pero si colocamos el símbolo $ luego del nombre de la base y especificamos el nombre de una variable (como salario_inicial) entonces: class(trabajadores$salario_actual) ## [1] &quot;numeric&quot; Ahora el programa entiende que lo que estamos solicitando es la clase de la variable salario_actual (que se encuentra en la base de datos trabajadores). Por ello nos dice que esta variable es de tipo numérico. Recuerda: los símbolos más usuales para ingresar a las partes de un objeto son el $ y los []. 2.3.4 Sugerencias Para un detalle mayor sobre los objetos en el R revisa este sitio: Seong, Tim (2018) Working with R Data Objects Sitio web de RPubs. Link También puedes explorar con las siguientes palabras clave: Objects in R Data structure in R Data types in R "],["conseguir-la-data.html", "Capítulo 3 Conseguir la data 3.1 Directorio de trabajo 3.2 GitHub y R 3.3 Manipular bases de datos 3.4 Web scrapping", " Capítulo 3 Conseguir la data 3.1 Directorio de trabajo Para comenzar el trabajo con el R Studio lo primero que debemos hacer es decirle al programa cuál es la ubicación de nuestra carpeta de trabajo (working directory). El working directory es el lugar en nuestra computadora (local) en el que están los archivos que vamos a utilizar durante nuestra sesión de trabajo. De la misma manera, es el lugar donde se encontrarán todos los documentos u objetos que vamos a producir en nuestro análisis (tablas, gráficos, bases de datos, entre otros). Antes de realizar cualquier análisis debemos seleccionar la carpeta que será nuestro directorio de trabajo, con el fin de mantener un orden durante toda la jornada. Para saber cuál es el directorio en el cual me encuentro trabajando sólo necesitamos redactar el siguiente comando. getwd() Una vez aplicado dicha función, el R Studio nos dirá la ubicación en la cual está nuestra carpeta. Por ejemplo: \"D:/Mis Documentos/R 3.1.1 Nuevo directorio Para ello tenemos dos opciones. La primera implica redactar un código, en el cual le decimos al programa la nueva dirección de nuestro directorio de trabajo. setwd(&quot;D:/Mis Documentos/Trabajos finales/examen parcial&quot;) La segunda opción es más sencilla. Esta consiste en el uso de la propia interfaz del R Studio. Debemos ir a Session &gt; Set Working Directory &gt; Choose Directory Image Luego de ello, seleccionamos la carpeta de nuestra preferencia y colocamos Abrir Image 3.2 GitHub y R Image Como mencionamos en el apartado anterior, lo primero que debemos hacer antes de iniciar nuestra sesión es seleccionar nuestro directorio de trabajo. Cuando hacemos eso, todos los archivos que utilizamos o produzcamos se van a alojar en un lugar en nuestra computadora. Una limitante de ello es que, obviamente, si nos quedamos en ese paso, siempre debemos estar en nuestra computadora para utilizar nuestros archivos. Por ello, una estrategia utilizada por muchos usuarios del R Studio, así como de otros lenguajes de programación, es utilizar la plataforma GitHub para poder trabajar con sus archivos desde la nube (desde el almacenamiento virtual de la propia plataforma). Seguramente en más de una ocasión hemos utilizado algunos programas de almacenamiento de datos en la nube como Google Drive o Dropbox. Lo que hacíamos era elegir nuestros archivos, guardarnos en nuestra cuenta de Google o Dropbox y, de esa manera, podíamos acceder a nuestros archivos desde cualquier computadora con acceso a internet. Image De la misma manera que el Google Drive o el Dropbox, el GitHub (creado el 2008) puede servir como un lugar de almacenamiento donde nosotros podemos guardar los documentos que vamos a utilizar en nuestra análisis: bases de datos, scripts, objetos producidos (tablas, gráficos), etc. Sin embargo, la característica más fundamental del GitHub no es sólo su capacidad de almacenamiento, sino que es un espacio específicamente diseñado para desarrolladores de software. De esta manera, uno puede alojar su proyecto en el sitio web y puede gestionar diversas versiones utilizando el sistema de control de version GIT. En otras palabas, el GitHub sirve para que un programador pueda subir el código en el que está trabajando, alojarlo en la nube y permitir el trabajo colaborativo con otros programadores. Para ello, se deben crear repositorios, los cuales son compartimientos específicos donde se colocan los archivos de un proyecto determinado. Ejemplo: Imagina que te encuentras desarrollando un script para el examen final, pero deseas trabajarlo colaborativamente. Para ello, creas un repositorio, subes el código en el que estás trabajando (script) y le das acceso a los miembros de tu grupo para que puedan editar el documento. El primer día tu puedes editar el documento, es la versión 1. En el segundo día, tu compañero hace un añadido, es la versión 2, así sucesivamente. El GitHub te permite colaborar en proyectos conjuntos y tener un historial de todas las versiones de un mismo proyecto de programación (como en este caso el script de tu análisis estadístico). En este libro vamos a explorar cómo utilizar el GitHub a través del Github Desktop. 3.2.1 Instalar el programa GIT Como se había mencionado, el GitHub se basa en el GIT, el cual es un software para controlar versiones. Por ello, antes de seguir con el GitHub debemos instalar este software en nuestra computadora. Para ello, entramos al siguiente enlace: https://git-scm.com/downloads Y luego, seleccionamos la opción más adecuada para nosotros según nuestro sistema operativo (Windows, Mac o Linux) Image Una vez instalado podemos seguir con los siguientes pasos. 3.2.2 Crear una cuenta en GitHub Para crear tu cuenta en GitHub es necesario entrar a: www.github.com Image Selecciones un nombre de usuario, un correo electrónico a asociar y una contraseña. Una vez te suscribas a la página ya tendrás un usuario donde podrás alojar tus repositorios. 3.2.3 Crear repositorio Para ello simplemente damos click a New: Image Detallamos cuál será el nombre de nuestro repositorio (en este caso mi_repositorio) y damos click a Crear Repositorio: Image Listo, ya tenemos la cuenta y nuestro repositorio creado. 3.2.4 Instalar GitHub Desktop Una vez que tengamos nuestra cuenta de GitHub y ya tengamos nuestro repositorio creado, viene el siguiente paso: agregar archivos y enlazar nuestro proyecto de R con la plataforma GitHub para almacenarlo en la nube y permitir el control de versiones. En otras palabras, deseo que mi carpeta de trabajo (working directory) esté enlazada con el GitHub. Para ello, a fin de hacer más sencillo el trabajo, sugiero instalar el software GitHub Desktop. Este es un programa para enviar/solicitar cambios en nuestros repositorios de forma más fácil y sencilla. Lo podemos descargar en: https://desktop.github.com/ Seleccionamos la opción más adecuada según nuestro SO y lo instalamos: Image Una vez esté instalado, abrimos el programa, ingresamos nuestro usuario y contraseña y ya estará enlazado con nuestra cuenta de GitHub en la nube. Esto quiere decir que nosotros podemos descargar nuestros archivos de nuestra cuenta y también enviar nuevas versiones de los mismos. 3.2.5 Clonar un repositorio (de la nube) en mi disco local Seleccionamos Clone Repository Image Como ya está enlazado con nuestro usuario, el programa nos va a solicitar que elijamos un repositorio de nuestra cuenta. También nos va a pedir que seleccionamos la ubicación que tendrá ese repositorio (carpeta) en nuestra computadora. Image Una vez terminemos estos pasos nos daremos cuenta que en la ubicación que hemos seleccionado se creó una carpeta con el mismo nombre que nuesro repositorio. 3.2.6 Agregar cambios a la nube (PUSH) Bien, ahora comencemos a utilizar el GitHub. Por ejemplo, entremos a R Studio y seleccionemos que el Directorio de trabajo sea la carpeta de nuestro repositorio (ver sección anterior). Image Creemos un Script para ver cómo funciona. Hemos creado un script en nuestra carpeta local que está linkeada a nuestro repositorio. Image Una vez hecho el cambio (creación de Script) nos vamos al GitHub Desktop. Image Recuerda que debes asegurarte que has guardado los cambios en cada archivo que has editado localmente. Lo que debemos ver en el GitHub Desktop es que en la parte izquierda figuran la lista de todos los cambios realizados (en este caso dice que agregamos un archivo que se llama Script1). En el panel derecho nos aparece el detalle de ese cambio (es decir el contenido en este caso). A continuación, le damos un nombre a ese cambio en la casilla que se encuentra en la parte inferior y seleccionamos Commit to Master. Image Finalmente para enviar esos cambios a nuestro repositorio le damos click a Push. Luego de eso, si vamos al GitHub (nube) nos vamos a dar cuenta que nuestro cambio (creación del Script1) ya figura en nuestro repositorio. Image De la misma manera que hemos creado este script y lo hemos subido, podemos hacer lo mismo con bases de datos, gráficos, tablas o con cualquier otro tipo de documento. La lógica siempre será la misma: editar los documentos -&gt; guardar los cambios localmente -&gt; Ir al GitHub Desktop -&gt; Verificar que los cambios realizados aparezcan en el panel -&gt; Darle un nombre a ese cambio -&gt; Poner Commit to Master -&gt; Colocar Push 3.2.7 Descargar cambios desde la nube (PULL) Si es que alguien ha realizado algún cambio a tu proyecto en la nube es fácilmente de descargar esos cambios localmente. Cuando abras tu GitHub Desktop vas a la parte superior que dice Fetch origin. Image Luego, si es que existe algún cambio realizado, vas a ver que automáticamente te sale la opción de Pull origin. Cuando presionas esa opción todos los cambios hechos en la nube se descargarán localmente. Recuerda siempre llevar un orden en tus ediciones de tal manera que no se genere conflictos en los documentos editados. Edita localmente, guarda cambios localmente, presiona Push origin. Edita en la nube, guarda los cambios en la nube, presiona Fetch Origin, presiona Pull origin. 3.2.8 Sugerencias Puedes buscar mayor información con las siguientes palabras clave: How to connect GitHub with R GitHub in R Studio How works GitHub Desktop 3.3 Manipular bases de datos Lo primero que tenemos que tener en claro en el proceso de manejo de bases de datos son tres cosas: Importar: Traer una base de datos de la nube o de nuestra computadora (local) hacia nuestro entorno de trabajo. Convertir: Cambiar el formato de una base de datos que tenemos en nuestro entorno de trabajo. Exportar: Guardar una base de datos que hemos trabajado como un nuevo archivo. Para ello, vamos a hacer uso del paquete rio, el cual es un conjunto de funciones que nos permiten realizar estas tres operaciones de una manera sencilla y rápida. Lo importante de este paquete a comparación de otros es que optimiza el proceso de importación/exportación de datos requiriendo una menor cantidad de código que otros paquetes. Puedes leer más sobre el paquete rio haciendo click a este enlace. Para utilizar este paquete debemos instalarlo y luego abrirlo. install.packages(&quot;rio&quot;) library(rio) 3.3.1 Importar localmente Una vez ya tengamos nuestro directorio de trabajo establecido, lo siguiente es abrir una base de datos. Imaginemos que en nuestro directorio de trabajo tenemos una base llamada trabajadores.sav Lo que queremos hacer es abrir la data en el R. Para ello, lo único que tenemos que hacer es utilizar la función import: data=import(&quot;trabajadores.sav&quot;) Lo que le estamos diciendo al programa es que importe la data trabajadores.sav y que le de el nombre de data. Recuerda que para escribirlo de esa manera el archivo(base de datos) ya debe encontrarse en tu carpeta de trabajo. Si lo tienes en alguna otra parte de tu computadora puedes escribir el enlace, como por ejemplo: C:/Mis documentos/Clase R/trabajadores.sav. 3.3.2 Importar desde la nube (GITHUB) En el apartado anterior habíamos revisado las ventajas de trabajar con repositorios en la nube. Por ello, también podemos importar datos a nuestro entorno de trabajo que no se encuentren en nuestro disco duro local sino alojado en una plataforma en la nube (como GitHub). Lo primero que tenemos que hacer es conseguir el link de la data. Para ello, debemos ir al repositorio donde está alojada la data, darle click al archivo que deseamos utilizamos y luego ubicar el botón que dice Descargar. Image Nosotros no vamos a presionar este botón (porque lo que haríamos sería descargar el archivo en nuestra computadora), sino que le vamos a dar click derecho y vamos a presionar copiar dirección de enlace. En el ejemplo de la imagen el enlace que copiamos es: https://github.com/DataPolitica/salidas/raw/master/Data/trabajadores.sav Luego de ello, ya en nuestro R, vamos a crear un objeto que se llame link y que sea equivalente a esa dirección. link=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/trabajadores.sav&quot; Luego, utilizaremos la función import para traer la data de la nube y le llamaremos trabajadores. trabajadores=import(link) Finalmente, podemos ver que en nuestro apartado de objetos (cuadrante superior derecho) ya figura la data que hemos importado desde la nube: Image 3.3.3 Convertir archivos Hasta este punto quizás los tipos de bases de datos más comunes que hemos visto son de formato Excel (.xls), SPSS (.sav) o los del propio R (.rda). Sin embargo, es muy probable que, a medida que avancemos en el uso del software, nos topemos con archivos de otros formatos. Hay un conjunto muy largo de extensiones, cada una de estas asociada a un programa en específico. Lo bueno del paquete rio es que nos permite convertir un archivo de un formato a otro de forma muy rápida. Por ejemplo, si tengo la base de datos de trabajadores.sav en mi carpeta de trabajo y deseo convertirla a formato .rda, sólo tengo que escribir el siguiente comando: convert(&quot;trabajadores.sav&quot;, &quot;trabajadores.rda&quot;) Cuando veamos nuestra carpeta vamos a ver que se ha creado una nueva versión de la base de datos pero con la extensión que le hemos indicado. Para más detalle sobre extensiones y programas asociados ver aquí. 3.3.4 Exportar archivos Finalmente, siguiendo la línea de lo comentado líneas arriba, para exportar un archivo que tengamos en nuestra sesión sólo debemos escribir la siguiente línea de comando: export(trabajadores, &quot;trabajadores.csv&quot;) Lo que le estamos diciendo al programa es que guarde la base de datos trabajadores (que viene a ser la data que tenemos abierta en nuestra sesión) como un archivo llamado trabajadores.csv. Si no deseamos exportar un archivo a .csv podemos indicarle el formato que queremos colcando la extensión respectiva. 3.3.5 Palabras clave How to import files in R Export and import packages Get my data in R 3.4 Web scrapping 3.4.1 Introducción Como sabemos, en el R Studio nosotros trabajamos sobre objetos. Pues bien, algunas veces nosotros podemos tener nuestros objetos (bases de datos, usualmente) de archivos que nos entregan directamente; sin embargo, otras veces la información se encuentra en diversas páginas web dentro del internet. Image El Web Sraping es una técnica para conseguir información de forma rápida y sistematizada por medio de algoritmos de búsquedas. Para el caso del R Studio, es necesario utilizar paquetes construidos específicamente para web scraping. En otras palabras, estos paquetes lo que hacen es entrar a una página web, extraen cierta información que le indiquemos y lo cargan a nuestra sesión de R Studio Algunos puntos a tener en cuenta Para hacer Web Scraping es necesario tener algunas consideraciones previas si es que antes no hemos explorado el contenido de una página web. De antemano sabemos que existen distintos tipos de páginas web, algunos parecen una hoja con letras (como si fuese una hoja de Word), pero muchas contienen ciertos elementos: videos, tablas, cuadros, imágenes, enlaces, entre otros. Entrar al mundo de cómo se construyen las páginas web es un objetivo que escapa a este apartado. Sin embargo, será necesario recordar que detrás de lo que vemos siempre existen un conjunto de códigos, denominado código fuente, que han servido para construir la página web. Sabiendo el código de ciertos elementos, como es el caso de las tablas, nosotros podemos decirle al R Studio que nos extraiga cierta información a nuestro entorno de trabajo. Para ello, necesitamos el paquete htmltab el cual sirve para poder extraer tablas de diversos tipos de páginas web construidas en lenguaje html. Es necesario anotar que existen muchos paquetes diseñados para web scraping. Otro paquete conocido es el paquete Rvest, cuyo contenido también te recomiendo revisar en este enlace. 3.4.2 Paso a paso 3.4.2.1 Identificar nuestra página web y la tabla que queremos descargar Primero tenemos que identificar nuestra página. En este caso entraremos a la página web de Wikipedia titulada Departamentos del Perú por IDH. En esta página web figura una tabla con los departamentos del Perú y los resultados que han obtenido en las distintas mediciones del Índice de Desarrollo Humano. Image Listo, tenemos ya identificada nuestra página web y el objeto que queremos extraer (tabla de resultados de IDH según departamento en el Perú) 3.4.2.2 Inspeccionar la página web y encontrar el código de la tabla Para ello tenemos que darle click derecho a nuestra tabla y seleccionar la opción inspeccionar. Image Vamos a ver que nos sale una subventana en la parte derecha que tiene muchos códigos. Tranquilos, estos códigos son la infraestructura de la página web. Cada letra y objeto que vemos en la vista normal tiene un código detrás con el cual ha sido programado. Literalmente estamos viendo la Matrix. Pues bien, luego de poner click derecho sobre nuestra tabla vamos ubicando el cursos en las líneas superiores hasta que veamos que la tabla se sombree por completo. Image Luego de eso, damos click derecho sobre ese código, seleccionamos Copy y Copy Xpath. Image El Xpath es como si fuese una ubicación del objeto que queremos extraer dentro de toda la infraestructura html de la página web. Vemos que en este caso lo que copiamos es lo siguiente: Image 3.4.2.3 Utilizar el paquete htmltab Una vez identificado la dirección de la página web y el Xpath del elemento que queremos descargar, ya podemos utilizar el paquete htmltab. Abrimos el paquete: library(htmltab) Creamos dos objetos. Primero un objeto que sea el link de la página web y otro objeto que sea el código Xpath. link_de_pagina= &quot;https://es.wikipedia.org/wiki/Anexo:Departamentos_del_Per%C3%BA_por_IDH&quot; codigoXPATH =&#39;//*[@id=&quot;mw-content-text&quot;]/div[1]/center/table&#39; Cuidado: Si observas bien, en un caso hemos usado las \"\" y en otro . Debes recordar que en el caso del Xpath vamos a utilizar las comillas simples. Estas se pueden incluir presionando ALT + 39. Luego, aplicamos la función htmltab en la cual le indicamos, en primer lugar, la dirección de la página (doc = link_de_página) y la ubicación del objeto que queremos extraer (which =codigoXPATH). A la base de datos extraída le daremos el nombre de data_IDH data_IDH = htmltab(doc = link_de_pagina, which =codigoXPATH) Para finalizar vemos que en la parte superior derecha de nuestro entorno de trabajo ya figura un objeto que es nuestra base de datos extraída. Para corroborar los elementos (variables) de nuestra base de datos utilizamos la función names: names(data_IDH) ## [1] &quot;#&quot; ## [2] &quot;Departamento&quot; ## [3] &quot;CÃ³digoÂ ISO&quot; ## [4] &quot;CÃ³digo Ubigeo&quot; ## [5] &quot;Capital&quot; ## [6] &quot;Ã\\215ndice de desarrollo humano 1993&quot; ## [7] &quot;Ã\\215ndice de desarrollo hbr/&gt;2000&quot; ## [8] &quot;Ã\\215ndice de desarrollo humano 2003&quot; ## [9] &quot;Ã\\215ndice de desarrollo humano 2005&quot; ## [10] &quot;Ã\\215ndice de desarrollo humano 2007&quot; ## [11] &quot;Ã\\215ndice de desarrollo humano 2012 â\\200&quot; ## [12] &quot;Ã\\215ndice de desarrollo humano 2019 â\\200&quot; También le podemos aplicar el comando str() para ver la estructura de nuestro data.frame: str(data_IDH) ## &#39;data.frame&#39;: 24 obs. of 12 variables: ## $ # : chr &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; ... ## $ Departamento : chr &quot;Lima&quot; &quot;Moquegua&quot; &quot;Arequipa&quot; &quot;Madre de Dios&quot; ... ## $ CÃ³digoÂ ISO : chr &quot;PE-LIM&quot; &quot;PE-MOQ&quot; &quot;PE-ARE&quot; &quot;PE-MDD&quot; ... ## $ CÃ³digo Ubigeo : chr &quot;15&quot; &quot;18&quot; &quot;04&quot; &quot;17&quot; ... ## $ Capital : chr &quot;Lima&quot; &quot;Moquegua&quot; &quot;Arequipa&quot; &quot;Puerto Maldonado&quot; ... ## $ Ãndice de desarrollo humano 1993 : chr &quot;0,6827&quot; &quot;0,6208&quot; &quot;0,6503&quot; &quot;0,5956&quot; ... ## $ Ãndice de desarrollo hbr/&gt;2000 : chr &quot;0,7440&quot; &quot;0,6661&quot; &quot;0,6352&quot; &quot;0,6206&quot; ... ## $ Ãndice de desarrollo humano 2003 : chr &quot;0,7189&quot; &quot;0,6499&quot; &quot;0,6526&quot; &quot;0,6010&quot; ... ## $ Ãndice de desarrollo humano 2005 : chr &quot;0,7039&quot; &quot;0,6435&quot; &quot;0,6463&quot; &quot;0,5997&quot; ... ## $ Ãndice de desarrollo humano 2007 : chr &quot;0,6788&quot; &quot;0,6532&quot; &quot;0,6479&quot; &quot;0,6304&quot; ... ## $ Ãndice de desarrollo humano 2012 â: chr &quot;0,6340&quot; &quot;0,6215&quot; &quot;0,5781&quot; &quot;0,5582&quot; ... ## $ Ãndice de desarrollo humano 2019 â: chr &quot;0,7073&quot; &quot;0,6589&quot; &quot;0,6425&quot; &quot;0,6136&quot; ... Ya tenemos nuestra data de IDH como un objeto en nuestro R Studio. "],["preprocesamiento.html", "Capítulo 4 Preprocesamiento 4.1 Configuración de variables 4.2 Datos perdidos", " Capítulo 4 Preprocesamiento 4.1 Configuración de variables Ya hemos visto que en el R existen diversos tipos de objetos; sin embargo, cuando realicemos nuestros análisis estadísticos normalmente requeriremos manejar tres tipos de objetos: factores no ordenados (para variables nominales), factores ordenados (para variables ordinales) y vectores numéricos (para variables numéricas). PROBLEMA Cuando usamos el R Studio es muy usual que, al inicio de la sesión, el programa considere todas las variables como numéricas. Esto puede ser un problema porque, si bien algunas veces existen números en las columnas, estas podrían hacer referencia a variables nominales u ordinales. Por ello, es necesario indicarle al programa con qué tipos de variables estamos trabajando. 4.1.1 Convertir a factor Recordemos qué variables tenemos en nuestra base de datos trabajadores: names(trabajadores) ## [1] &quot;id&quot; &quot;sexo&quot; &quot;fechnac&quot; &quot;educ&quot; ## [5] &quot;catlab&quot; &quot;salario_actual&quot; &quot;salario_inicial&quot; &quot;antiguedad&quot; ## [9] &quot;experiencia&quot; &quot;minoría&quot; &quot;directivo&quot; Vamos a solicitar que el R nos diga qué clase de objeto es la variable sexo: class(trabajadores$sexo) ## [1] &quot;numeric&quot; Nos damos cuenta que para el programa estamos ante una variable numérica (puesto que está codificado). Sin embargo, debemos convertirlo a factor para poder utilizarlo más adelante como variable nominal. Para ello utilizamos la función as.factor() de la siguiente manera: trabajadores$sexo = as.factor(trabajadores$sexo) Con esto le hemos dicho al programa que convierta a factor la variable sexo y que la imprima con el mismo nombre (es decir que lo reemplace). Para corroborar que hemos cambiado el tipo de vector de forma satisfactoria solicitamos nuevamente la clase de la variable sexo: class(trabajadores$sexo) ## [1] &quot;factor&quot; Ahora nos damos cuenta que efectivamente ahora la variable sexo es de tipo factor. Adicionalmente, tenemos que especificar cuál es el significado de cada uno de los niveles del factor (cada categoría). Si solicitamos los niveles de la variable, nos damos cuenta que existen dos niveles: el 0 y el 1. levels(trabajadores$sexo) ## [1] &quot;0&quot; &quot;1&quot; De acuerdo al manual de la base de datos (metadata) sabemos que 0 equivale a Hombre y 1 a Mujer. Por ello, le asignamos dichas etiquetas a cada nivel con la función c(): levels(trabajadores$sexo)&lt;-c(&quot;Hombre&quot;,&quot;Mujer&quot;) Verificamos solicitando nuevamente los niveles de la variable sexo: levels(trabajadores$sexo) ## [1] &quot;Hombre&quot; &quot;Mujer&quot; Nota que en el código hemos puesto primero Hombre y luego Mujer. Esto se debe a que cuando colocamos las etiquetas debemos seguir el orden de los niveles del factor (en este caso 0 y 1) 4.1.2 Estructura de una variable Una forma adicional de corroborar el tipo de vector que tenemos y también ver rápidamente los niveles y los códigos de los mismos es a través del uso de la función str(): str(trabajadores$sexo) ## Factor w/ 2 levels &quot;Hombre&quot;,&quot;Mujer&quot;: 2 2 1 1 2 2 2 1 1 1 ... Esta función nos dice que estamos ante un factor de 2 niveles, los cuales han sido etiquetados como Hombre y Mujer. Finalmente a la derecha aparecen los primeros valores del vector a modo de vista previa. Es posible que si aplicamos esta función a otras variables nos salgan más datos: str(trabajadores$salario_actual) ## num [1:474] 57000 40200 21450 21900 45000 ... ## - attr(*, &quot;label&quot;)= chr &quot;Salario actual&quot; ## - attr(*, &quot;format.spss&quot;)= chr &quot;DOLLAR8&quot; ## - attr(*, &quot;display_width&quot;)= int 12 ## - attr(*, &quot;labels&quot;)= Named num 0 ## ..- attr(*, &quot;names&quot;)= chr &quot;Ausente&quot; Esto se debe a que dentro de la estructura de la variable se le han detallado más componentes (etiqueta, formato, longitud, entre otros); sin embargo, siempre lo más importante para nuestro análisis va a presentarse en la primera línea. En este último ejemplo nos dice que la variable salario_actual es un vector numérico, tiene 474 observaciones y nos muestra los primeros valores como vista previa. 4.1.3 Convertir en ordinal Abrimos nuestra base de datos EDA desde nuestro repositorio GitHub: library(rio) link=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/eda.sav&quot; EDA=import(link) Vemos qué variables tenemos en la base de datos: names(EDA) ## [1] &quot;id&quot; &quot;region&quot; &quot;consipol&quot; &quot;edad&quot; &quot;intecamp&quot; &quot;intecampR&quot; ## [7] &quot;clintpre&quot; &quot;gorepre&quot; &quot;gbushpre&quot; &quot;aborto&quot; &quot;anonac&quot; &quot;educ&quot; ## [13] &quot;sexo&quot; &quot;ingresos&quot; &quot;marital&quot; &quot;voto96&quot; &quot;quien96&quot; &quot;su_ecopas&quot; ## [19] &quot;clintpst&quot; &quot;gorepst&quot; &quot;gbushpst&quot; &quot;relig&quot; &quot;voto00&quot; &quot;confipol&quot; ## [25] &quot;confipolR&quot; &quot;consipolR&quot; Vamos a trabajar con la variable confipolR la cual hace referencia a Confianza en la política. Esta es una variable ordinal en donde: 1 equivale a Baja; 2 equivale a Media; y 3 equivale a Alta. Sin embargo, si solicitamos la clase de la variable vemos que es numérica: class(EDA$confipolR) ## [1] &quot;numeric&quot; Por ello es necesario aplicar la función ordered(). En el siguiente comando le decimos que considere como ordinal a la variable confipolR. EDA$confipolR=ordered(EDA$confipolR) Corroboramos que hemos dado el formato adecuado solicitando nuevamente la clase del vector y viendo que efectivamente es un factor ordenado: class(EDA$confipolR) ## [1] &quot;ordered&quot; &quot;factor&quot; Finalmente, le asignamos las etiquetas a los niveles (Baja, Media y Alta): levels(EDA$confipolR) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; levels(EDA$confipolR)&lt;-c(&quot;Baja&quot;,&quot;Media&quot;, &quot;Alta&quot;) levels(EDA$confipolR) ## [1] &quot;Baja&quot; &quot;Media&quot; &quot;Alta&quot; 4.2 Datos perdidos Te recomiendo mirar el siguiente tutorial para ver el proceso de identificación de valores perdidos en una base de datos. "],["análisis-exploratorio-de-datos.html", "Capítulo 5 Análisis exploratorio de datos 5.1 Para nominales 5.2 Para ordinales 5.3 Para numéricas 5.4 Análisis bivariado", " Capítulo 5 Análisis exploratorio de datos Como sabemos, los estadísticos de tendencia central van a depender del tipo de variable que estemos analizando. Para practicar este apartado vamos a utilizar la base de datos de Lapop del año 2017. Lapop es el Proyecto de Opinión Pública de América Latina implementado por la Universidad de Vanderbilt, el cual es un proyecto de investigación multinacional especializado en el desarrollo, implementación y análisis de encuestas de opinión pública. Abrimos la base de datos desde nuestro repositorio: library(rio) link=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/sub_lapop.sav&quot; lapop=import(link) Esta base de datos ha sido editada con fines didácticos (idioma, recodificación, etc). 5.1 Para nominales 5.1.1 Preparación Selecciones la variable urbanorural y procedemos a configurarla adecuadamente. Primero identifiquemos cómo el R está leyendo la variable. str(lapop$urbanorural) ## num [1:2153] 2 2 2 2 2 2 2 2 2 2 ... ## - attr(*, &quot;label&quot;)= chr &quot;Urbano / Rural&quot; ## - attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot; ## - attr(*, &quot;display_width&quot;)= int 9 ## - attr(*, &quot;labels&quot;)= Named num [1:2] 1 2 ## ..- attr(*, &quot;names&quot;)= chr [1:2] &quot;Urbano&quot; &quot;Rural&quot; class(lapop$urbanorural) ## [1] &quot;numeric&quot; Luego, al ver que aún se encuentra como numérico, entonces lo convertimos en factor: lapop$urbanorural=as.factor(lapop$urbanorural) class(lapop$urbanorural) ## [1] &quot;factor&quot; Verificamos los niveles y, de acuerdo con la metadata, le asignamos las etiquetas a cada uno de los mismos. levels(lapop$urbanorural) ## [1] &quot;1&quot; &quot;2&quot; levels(lapop$urbanorural)&lt;-c(&quot;Urbano&quot;,&quot;Rural&quot;) levels(lapop$urbanorural) ## [1] &quot;Urbano&quot; &quot;Rural&quot; Asimismo, podemos solicitar una tabla que nos muestre las proporciones por cada categoría. Para ello, utilizamos la función prop.table(). Cuando escribimos esta función hay que tener en cuenta que la tenemos que aplicar sobre la tabla de frecuencias normal (que aplicamos anteriormente): prop.table(table(lapop$urbanorural)) ## ## Urbano Rural ## 0.6149559 0.3850441 Si queremos los porcentaje hacemos lo mismo pero al final le decimos que lo multiple por 100 (*100): prop.table(table(lapop$urbanorural))*100 ## ## Urbano Rural ## 61.49559 38.50441 Ya tenemos la variable lista para aplicar técnicas de análisis descriptivo. 5.1.2 Estadísticos descriptivos Lo primero que podemos hacer es solicitar la función summary. Esta función nos va a dar una mirada rápida al contenido de nuestra variable. En el caso de ser factor, nos va a mostrar las frecuencias (incluye los NA si los hubiera): summary(lapop$urbanorural) ## Urbano Rural ## 1324 829 Como sabemos el estadístico más idóneo para variables nominales es la moda. Por ello, hacemos uso del paquete DescTools y de la función Mode(): library(DescTools) Mode(lapop$urbanorural) ## [1] Urbano ## attr(,&quot;freq&quot;) ## [1] 1324 ## Levels: Urbano Rural Lo que nos dice el resultado es que la moda es la categoría Urbano y nos indica la frecuencia. Otra opción también es solicitar una tabla simple para ver la frecuencia de cada categoría. table (lapop$urbanorural) ## ## Urbano Rural ## 1324 829 5.1.3 Gráficos Lo primero que podemos solicitar es un diagrama de pie o de sectores. Nótese que primero debemos crear un objeto que sea la tabla de la variable que deseamos graficar, en este caso, de urbano rural. De esa manera, el programa podrá utilizar los datos y plasmarlos en un gráfico. mi_tabla &lt;- table(lapop$urbanorural) pie(mi_tabla) Image Es recomendable graficar un máximo de 7 sectores. Si colocamos una varaible con más sector puede resultar confusa la interpretación. También podemos solicitar un diagrama de barras. barplot(mi_tabla) Image Agregando más detalles a nuestros gráficos Hasta este momento hemos visto que podemos solicitar gráficos de una forma muy práctica. Sin embargo, nosotros podemos solicitar un producto más elaborado en la medida en que agreguemos más características al código. Por ejemplo, si deseamos un diagrama de barras azul escribimos: barplot(mi_tabla, col=&quot;blue&quot;) Image Si deseamos un diagrama de barras azul y con título escribimos: barplot(mi_tabla,col=&quot;blue&quot;, main=&quot;Casos según su lugar de procedencia&quot;) Image Como nos damos cuenta, nosotros podemos ir agregando más características a nuestro código. Es posible que recuerdes ejemplos de códigos de programación que son líneas interminables. Eso es así porque los programadores elaboran productos muy específicos y que, en su mayoría de veces, requieren la especificación de muchas características. Nuestro objetivo será avanzar en el uso de estos códigos de programación para poder, al igual que los programadores, elaborar análisis estadísticas cada vez más complejos y específicos. 5.2 Para ordinales Abrimos la base de datos LAPOP desde nuestro repositorio: library(rio) link=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/sub_lapop.sav&quot; lapop=import(link) 5.2.1 Preparación Esta vez vamos a utilizar la variable Interés en la política. Procedemos a configurarla adecuadamente. Primero identifiquemos cómo el R está leyendo la variable. str(lapop$interes) ## num [1:2153] 2 2 1 1 1 2 2 2 2 3 ... ## - attr(*, &quot;label&quot;)= chr &quot;Interés en la política&quot; ## - attr(*, &quot;format.spss&quot;)= chr &quot;F8.2&quot; ## - attr(*, &quot;display_width&quot;)= int 11 ## - attr(*, &quot;labels&quot;)= Named num [1:4] 1 2 3 4 ## ..- attr(*, &quot;names&quot;)= chr [1:4] &quot;Nada&quot; &quot;Un poco&quot; &quot;Algo&quot; &quot;Mucho&quot; class(lapop$interes) ## [1] &quot;numeric&quot; Luego, al ver que aún se encuentra como numérico, entonces lo convertimos en factor ordenado: lapop$interes=ordered(lapop$interes) class(lapop$interes) ## [1] &quot;ordered&quot; &quot;factor&quot; Verificamos los niveles y, de acuerdo con la metadata, le asignamos las etiquetas a cada uno de los mismos. En este caso los significados son: 1, Nada; 2, Poco; 3, Algo; y 4, Mucho. levels(lapop$interes) ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; levels(lapop$interes)&lt;-c(&quot;Nada&quot;,&quot;Poco&quot;, &quot;Algo&quot;, &quot;Mucho&quot;) levels(lapop$interes) ## [1] &quot;Nada&quot; &quot;Poco&quot; &quot;Algo&quot; &quot;Mucho&quot; Ya tenemos la variable lista para aplicar técnicas de análisis descriptivo para ordinales. 5.2.2 Estadísticos descriptivos Al igual que la sección anterior, podemos solicitar la función summary() para que nos muestre las frecuencias por cada categoría (en este caso tampoco tenemos NA´´s): summary(lapop$interes) ## Nada Poco Algo Mucho ## 632 787 532 202 Utilizando el paquete DescTools podemos solicitar la moda, con la función Mode(); y la mediana, con la función Median(): library(DescTools) Mode(lapop$interes) ## [1] Poco ## attr(,&quot;freq&quot;) ## [1] 787 ## Levels: Nada &lt; Poco &lt; Algo &lt; Mucho Median(lapop$interes) ## [1] Poco ## Levels: Nada &lt; Poco &lt; Algo &lt; Mucho Lo que nos dice el resultado es que la moda es la categoría Poco. La mediana nos dice que, si ordenamos los resultados de menor a mayor, el valor central es Poco. También podemos interpretarlo como que al menos el 50% de los casos tienen poco interés en la política. Otra opción, al igual que las nominales, es solicitar una tabla simple para ver la frecuencia de cada categoría. table (lapop$interes) ## ## Nada Poco Algo Mucho ## 632 787 532 202 5.2.3 Gráficos Primero creamos un objeto que sea la tabla de la variable que deseamos graficar, en este caso, interés por la política. mi_tabla &lt;- table(lapop$interes) mi_tabla ## ## Nada Poco Algo Mucho ## 632 787 532 202 Solicitamos un diagrama de pie o sector con la función pie(): pie(mi_tabla) Image Solicitamos un diagrama de barras con la función barplor(): barplot(mi_tabla) Image 5.3 Para numéricas 5.3.1 Preparación Abrimos la base de datos LAPOP desde nuestro repositorio: library(rio) link=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/sub_lapop.sav&quot; lapop=import(link) Seleccionamos la variable ingresos 5.3.2 Estadísticos descriptivos Solicitar la función summary() y vamos a ver que el resultado variable significativamente de los resultados de las variables categóricas: summary(lapop$ingresos) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1316 2661 3010 3012 3341 4667 Como vemos, el summary ahora nos muestra los principales estadísticos de una variable numérica, es decir: mínimo, 1er cuartil, mediana, media o promedio, 3er cuartil y máximo. Siempre que tengamos una variable numérica comencemos por solicitar esta función. 5.3.3 Estadísticos de dispersión La lógica es la misma, colocamos la función y entre paréntesis el nombre de la variable: Si deseamos la desviación estándar utilizamos la función sd(): sd(lapop$ingresos) ## [1] 498.6063 Si deseamos la varianza utilizamos la función var(): var(lapop$ingresos) ## [1] 248608.3 También podemos pedir estadísticos de dispersión. Para solicitar la asimetría y curtosis primero abrimos el paquete e1071: library(e1071) Para la asimetría utilizamos la función skewness(): skewness(lapop$ingresos) ## [1] 0.0544436 Para la curtosis utilizamos la función kurtosis(): kurtosis(lapop$ingresos) ## [1] -0.0678835 5.3.4 Gráficos En este caso, como estamos ante una variable numérica, no necesitamos crear una tabla antes de solicitar los gráficos. Histograma Solicitemos un histograma con la función hist(): hist(lapop$ingresos) Image Diagrama de cajas o boxplot Solicitemos un diagrama de cajas con la función boxplot(): boxplot(lapop$ingresos) Image 5.4 Análisis bivariado 5.4.1 Tablas de contingencia Abrimos la base de datos LAPOP desde nuestro repositorio: library(rio) link=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/sub_lapop.sav&quot; lapop=import(link) Verificamos y configuramos adecuadamente las variables que utilizaremos lapop$urbanorural=as.factor(lapop$urbanorural) levels(lapop$urbanorural)&lt;-c(&quot;Urbano&quot;,&quot;Rural&quot;) lapop$sexo=as.factor(lapop$sexo) levels(lapop$sexo)&lt;-c(&quot;Hombre&quot;,&quot;Mujer&quot;) Una vez que hemos identificamos dos variables categóricas lo primeros que podemos solicitar es una tabla de contingencia. Ante de seguir te sugiero ver el siguiente tutorial para solicitar tablas de contigencias: Como vimos en el video, podemos pedir tablas de contingencia con la función table(). Hagamos una tabla para las variables urbanorural y sexo: Primero hallemos una tabla de contingencia simple, con sólo las frecuencias. La llamaremos tabla1: tabla1 &lt;- table(lapop$urbanorural, lapop$sexo) tabla1 ## ## Hombre Mujer ## Urbano 687 637 ## Rural 434 395 Podemos agregarle los totales marginales escribiendo la siguiente función addmargins() addmargins(tabla1) ## ## Hombre Mujer Sum ## Urbano 687 637 1324 ## Rural 434 395 829 ## Sum 1121 1032 2153 Ahora, pidamos una tabla de contingencia con porcentaje Tenemos que hacer referencia a la tabla creada anteriormente y usar el comando prop.table() y lo multiplicamos por 100. La llamaremos tabla2: tabla2 &lt;- prop.table(tabla1)*100 tabla2 ## ## Hombre Mujer ## Urbano 31.90896 29.58662 ## Rural 20.15792 18.34649 Vemos que nos da los valores totales, pero nosotros queremos sólo los porcentaje por columna. Para ello, debemos hacer referencia a las columnas dentro del comando agregando el número 2 (si ponemos 1 aparecerán los porcentaje por filas) tabla3 &lt;- prop.table(tabla1, 2)*100 tabla3 ## ## Hombre Mujer ## Urbano 61.28457 61.72481 ## Rural 38.71543 38.27519 Por último, podemos agregarle los totales marginales escribiendo la siguiente función addmargins() addmargins(tabla3) ## ## Hombre Mujer Sum ## Urbano 61.28457 61.72481 123.00937 ## Rural 38.71543 38.27519 76.99063 ## Sum 100.00000 100.00000 200.00000 5.4.2 Una numérica y una categórica Para mostrar los descriptivos de una variable numérica según una variable categórica tenemos que considerar a esta última como grupos. De esta manera, lo que hacemos en realidad es la comparación de la numérica entre 2 o más grupos. Para ello, utilizamos el paquete psych() library(psych) Para describir la varible podemos utilizar la función describeBy(). Notemos que primero debemos poner la variable numérica y luego el grupo de comparación. Por ejemplo, obtengamos los estadísticos descriptivos de la variable Edad según si la persona pertenece al ámbito rural o urbano (categórica/grupos): describeBy(lapop$edad,group=lapop$urbanorural) ## ## Descriptive statistics by group ## group: Urbano ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 1324 37.79 14.59 35 36.51 14.83 18 86 68 0.67 -0.27 0.4 ## ------------------------------------------------------------ ## group: Rural ## vars n mean sd median trimmed mad min max range skew kurtosis se ## X1 1 829 36.96 13.68 35 35.84 14.83 18 80 62 0.63 -0.25 0.48 También podemos solicitar un diagrama de cajas o boxplot según los grupos: boxplot(lapop$edad~lapop$urbanorural) Image 5.4.3 Dos variables numéricas Utilicemos la base de datos trabajadores: library(rio) base_trabajadores=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/trabajadores.sav&quot; trabajadores=import(base_trabajadores) Para analizar la relación entre dos variables numéricas es muy común referirse al gráfico de dispersión. Para ello, solicitamos el gráfico con la función plot(). Entre paréntesis colocar las dos variables numéricas: el salario inicial y el salario actual de los trabajadores de una empresa. plot(trabajadores$salario_actual, trabajadores$salario_inicial) Image Podemos especificar más elementos de nuestro gráfico de dispersión. Agreguemos título del gráfico y etiquetas de los ejes X e Y: plot(trabajadores$salario_actual, trabajadores$salario_inicial, main=&quot;Relación entre salario inicial y salario final&quot;, xlab=&quot;Salario actual&quot;, ylab=&quot;Salario final&quot;) Image "],["manipulación-con-tidyverse.html", "Capítulo 6 Manipulación con Tidyverse 6.1 Gráficos con ggplot2", " Capítulo 6 Manipulación con Tidyverse 6.1 Gráficos con ggplot2 6.1.1 Introducción Image Como hemos visto, hasta este momento, para realizar nuestros distintos gráficos hemos utilizado los comandos que ya están preinstalados en el R Studio (barplot(), hist(), pie(), entre otros). Sin embargo, una limitante de estas funciones es que los gráficos son muy simples. Por ello, es común la utilización de otros paquetes que, entre sus funciones, contemplan herramientas para graficar variables de una forma más completa y con mejor presentación. Uno de los paquetes más conocidos por su potencia y también por su adaptabilidad es el ggplot2. El ggplot2 es un paquete de trazado que nos ayuda a simplificar la creación de gráficos complejos. Las características del comando (a diferencia de las funciones básicas de gráficos) nos permite agregar más propiedades visuales. Lo clave de este paquete es que funciona de forma aglomerativa, agregando elemento por elemento, por ello, analizaremos la estructura del código. 6.1.2 Estructura del código Cuando veamos la función ggplot() tenemos que identificar los siguiente elementos básicos: Base de datos (data) Es la base de datos de donde obtenemos la información a graficar. Estéticas (aes) Es una lista de asignaciones estéticas para utilizar en el gráfico. De una forma sencilla, podríamos verlo como la sección que describe los datos que serán graficados (variables), así como algunas características principales (color, tamaño, entre otros). Capas (geom) También denominadas capas geométricas. Una vez que tengamos la data identificada y las asignaciones incluidas, agregamos las capas, las cuales son las indicaciones directas de qué graficar. Te darás cuenta que si no detallas este punto, te aparecerá un gráfico en blanco. Dentro de los tipos de capas más comunes para nuestros fines podemos encontrar: Tipo de capa comando a agregar Dispersión + geom_point() Líneas + geom_line() Histogramas + geom_histogram() Barras + geom_bar() Boxplot + geom_boxplot() Dependiente de lo que queremos graficar, deberemos agregar ese frase en nuestro comando. 6.1.3 Utilizando ggplot2 paso a paso 6.1.3.1 Conseguir la data y abrir el paquete Conseguir la base de datos:: library(rio) base_trabajadores=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/trabajadores.sav&quot; trabajadores=import(base_trabajadores) Se debe instalar el paquete con la función install.packages(ggplot2). Luego, abrirmos el paquete a utilizar. library(ggplot2) De la misma manera, como hemos comentado en secciones anterior, si deseamos utilizar variables debemos verificar que estén siendo leídas de forma adecuada (las númericas como vectores numéricos y las categóricas como factores, se no ordenados u ordenados). 6.1.3.2 Utilizar la función ggplot() e indicarle la data Vamos a ir construyendo el comando paso a paso con la finalidad de que el lector pueda identificar cada componente de la función. Estas luego serán escritas directamente y en un solo momento. Primero le decimos al comando ggplot() qué data vamos a utilizar: ggplot(data = trabajadores) Image Si corremos este comando sólo con esa informació nos mostrará una sección en blanco puesto que debemos seguir detallando las parte necesarias para construir el gráfico. 6.1.3.3 Decirle qué estéticas va a considerar Como comentamos arriba, las estéticas son los componentes que serán agregados en el gráfico. En otras palabras, los datos a graficar (mapping). En este caso, vamos a decirle que considere que el eje x del gráfico represente el salario inicial del trabajador y el eje y el salario actual: ggplot(trabajadores, mapping = aes(x=salario_inicial, y= salario_actual)) Image Hasta el momento vemos que ya aparecen los ejes x e y pero aún no nos aparece ningún gráfico. Ya detallamos la data, ya detallamos los ejes, ahora queda precisar qué gráfico queremos. 6.1.3.4 Agregar capas En este caso, al estar trabajando con dos numéricas podemos decirle al comando que nos muestre un gráfico de dispersión. Entonces, tenemos que agregar la capa necesaria, es decir: + geom_point() ggplot(trabajadores, mapping = aes(x=salario_inicial, y= salario_actual)) + geom_point() Image 6.1.3.5 Guardar el gráfico Una vez tengamos el gráfico terminado podemos guardarlo como un archivo .png con el siguiente comando: ggsave(&quot;mi_grafico.jpg&quot;) ## Saving 7 x 5 in image Luego de este comando verás que efectivamente se guardo la imagen con ese nombre en tu directorio de trabajo. "],["introducción-a-la-estadística-inferencial.html", "Capítulo 7 Introducción a la estadística inferencial 7.1 Conceptos basicos 7.2 Intervalos de confianza 7.3 Pruebas de hipótesis", " Capítulo 7 Introducción a la estadística inferencial 7.1 Conceptos basicos Estos son los conceptos que veremos a lo largo del libro y que serán indispensables para comprender cada uno de los apartados: Objetivo de la Estadística Inferencial: Realizar un cálculo de los parámetros poblacionales a partir de data de una muestra representativa. Población: Conjunto total de individuos u objetos que tienen el mismo conjunto de características (variables) y del cual queremos obtener información. Muestra: Parte de la población, es obtenida a través de un determinado proceso de muestreo. El objetivo es que sea lo más representativa posible de la población de interés. Parámetro: Una característica de la población. Ej: el promedio de la edad de todos los individuos de la población. Estadístico: Una característica de la muestra. Ej: el promedio de la edad de todos los individuos de mi muestra. 7.1.1 Proceso de la estadística inferencial La estadística implica el estudio de la población a través de una muestra. Esto quiere decir que con la información de un subconjunto de individuos/objetos (estadísticos) vamos a inferir las características de toda la población de individuos/objetos (parámetros). En otras palabras, con algunos datos podemos realizar generalizaciones, estimaciones y predicciones para conocer las características de una población en particular. Para realizar tal proceso nos valemos de un conjunto de técnicas y estrategias desarrolladas que utilizan cálculos de probabilidades para poder estimar los parámetros. Recuerda que la muestra debe ser representativa. No es objetivo de este libro hacer un estudio sobre los métodos de muestreo; sin embargo, debes recordar que sólo el proceso de diseño muestral puede ser un trabajo largo y que requiere mucha rigurosidad. Muchos estudios estadísticos tienen el problema que llegan a conclusiones basados en muestras no representativas. 7.1.2 Métodos de estimación Dentro de la estadística inferencial existen dos métodos de estimación del parámetro (característica de la población): el estimador puntual, la estimación por intervalo. El estimador puntual es cuando nosotros representamos nuestra estimación utilizando un sólo número. Por ejemplo: nosotros realizamos una encuesta para saber la aprobación presidencial en el país y obtenemos que un 60% de la muestra aprueba la gestión del presidente. A través de este número (60%) nosotros podríamos hacernos una idea del parámetro (si es que la muestra es representativa). Este tipo de estimadores son usados mayormente por los medios de comunicación para problematizar cierto tema; sin embargo, no es una información que nos ayude mucho al final de cuentas. Estimación por intervalo: Es un método que no nos entrega un sólo número sino que nos indica un intervalo en el cual se podría encontrar el parámetro población. Este se calcula a partir del estimador puntual y se le agrega un margen de error Ej: siguiendo el ejemplo anterior, este método nos podría indicar que el porcentaje de personas que aprueban la gestión del presidente en la población se puede encontrar entre 56% y 64%. 7.1.3 El rol de la computadoras y los software estadísticos Como imaginarás, hace algunas décadas todos los cálculos necesarios para realizar análisis estadísticos se realizaban a mano, esto quiere decir que los estadísticos hacían cálculos y todos los procedimientos por ellos mismo utilizando lápiz y papel. Sin embargo, gracias al avance tecnológicos hoy día tenemos las computadoras y los software estadísticos (como el R, SPSS, Stata, entre otros) que hacen los cálculos complejos por nosotros y nos brindan los resultados en muy poco tiempo. Esto, si bien es muy útil y obviamente alivia de un trabajo complejo al investigador, también ha ocasionado que muchas personas utilicen el software de forma poco rigurosa, llegando a conclusiones que muchas veces no guardan relación con la teoría que está detrás del cálculo. Por ello, antes de entrar a uno de los temas a ver aquí serán importantes dos pasos: Revisar adecuadamente la base teórica de los métodos de estadística inferencial a utilizar. Esto permitirá saber qué es lo que estamos haciendo y para qué. Revisar las funciones que utilizaremos: Estamos usando el R y en este programa, como comentamos anteriormente, hay muchas formas de llegar al mismo punto y hay muchos paquetes (y funciones) que nos permiten hacer lo mismo. Sin embargo, cada una de estas tienen ciertas particularidades que fueron diseñadas por sus creadores (recordemos que R es un software libre y las funciones son creadas por una comunidad de usuarios), por ello, es necesario saber bien qué hacen las funciones que aplicamos y cuáles son sus características. 7.2 Intervalos de confianza Te recomiendo ver el siguiente tutorial para el cálculo de intervalos de confianza en el R Studio: 7.3 Pruebas de hipótesis Luego de los intervalos de confianza, las pruebas de hipótesis son los métodos más utilizados para realizar inferencia estadística. Estas pruebas se basan en el uso de las probabilidades para realizar sus cálculos. El objetivo final es verificar qué tan probable es que una hipótesis sobre la población sea cierta. . Resume evidencia para averiguar si una hipótesis es probable. Recuerda una hipótesis es una afirmación sobre la población. Usualmente presentado como la atribución de una característica al parámetro poblacional. Las pruebas de hipótesis tienen 5 pasos bien definidos: 7.3.1 Supuestos Cada prueba de hipótesis tiene ciertas condiciones en las cuales se puede aplicar. Uno de los supuestos principales requeridos es que el proceso de muestreo (recojo de información) haya sido realizado de forma aleatoria. Image El segundo supuesto más recurrente es que la variable a utilizar tenga distribución normal. Gracias al teorema del límite central, con N grande (mayor a 121) podemos asumir normalidad 7.3.2 Hipótesis Cada prueba de medias tiene dos hipótesis sobre la población: la hipótesis nula y la hipótesis alternativa. Nosotros vamos a poner a prueba la hipótesis nula (H0) mediante la recolección de evidencia en los datos encontrados en la muestra que anteriormente hemos recogido (o nos han entregado). Algunos ejemplos de hipótesis según el objetivo de la prueba: 7.3.3 Test estadístico Son el instrumento para validar o rechazar las hipótesis. Ellos tratan de distinguir lo que es plausible de lo que es muy poco verosímil, en el marco de un objetivo dado. Existen diversos test estadísticos dependiendo del objetivo del investigador: Pruebas T (comparación de media en dos grupos), Anova de un factor (comparación de medias en más de dos grupos), Chi cuadrado (asociación), entre los más resaltantes. 7.3.4 El p-valor (p-value) Es una medición estadística que va de 0 a 1. Se usa para el contraste de hipótesis. Si cumple con la condición de ser menor al nivel de significancia (alpha = 0.05 a un 95% de confianza) impuesto arbitrariamente, entonces la hipótesis nula será, eventualmente, rechazada. El p-valor es un número que veremos en todos nuestros análisis a lo largo de este manual. Si bien la explicación de tal término está relacionada a un conjunto de elementos teóricos de estadística, puedes ver el siguiente video que te permitirá tener una idea general de para qué sirve este número. 7.3.5 Conclusión Hasta este punto hemos obtenido un conjunto de números en nuestros calculos. Ahora la parte más importante es la interpretación de esos números. Es muy usual que un estudiante realice todos los pasos anteriores de forma eficiente pero tenga problemas al momento de generar conclusiones. Como dijimos, la finalidad de la estadística inferencial es establecer conclusiones sobre la población, por ello, estas deben ser presentadas de forma clara y rigurosa. Para ello, debemos seguir el siguiente flujograma: Una vez que sabemos el valor de significancia (p-valor) y si rechazamos o no rechazamos la hipótesis nula, vamos a redactar nuestra conclusión. Para ello es necesario incorporar los siguiente elementos en el fraseo: nombre de la prueba, resultado del p valor, si rechazamos o no rechazamos la hipótesis nula, y la idea o conclusión final. Ejemplo: Estamos ante una Prueba T de comparación de medias de la variable Ingreso en hombres y mujeres, cuya hipótesis nula es que Las medias son iguales en los dos grupos analizados y el p-valor que obtuvimos es 0.03. Con estos insumos redactamos: Luego de realizar la Prueba T y de acuerdo al p-valor obtenido (0.03), podemos rechazar la hipótesis nula de que las medias de la variable Ingreso son iguales en los dos grupos analizados (hombres y mujeres) y concluir que las medias son diferentes en ambos grupos poblacionales. "],["regresión-lineal.html", "Capítulo 8 Regresión Lineal 8.1 Regresión Lineal Simple 8.2 Regresión Lineal Múltiple 8.3 Verificación de supuestos", " Capítulo 8 Regresión Lineal 8.1 Regresión Lineal Simple Te sugiero revisar el siguiente tutorial para el cálculo de un modelo de regresión simple en {{&lt; icon name=r-project pack=fab &gt;}}: 8.1.1 Preparación library(rio) base_trabajadores=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/trabajadores.sav&quot; trabajadores=import(base_trabajadores) attach(trabajadores) names(trabajadores) ## [1] &quot;id&quot; &quot;sexo&quot; &quot;fechnac&quot; &quot;educ&quot; ## [5] &quot;catlab&quot; &quot;salario_actual&quot; &quot;salario_inicial&quot; &quot;antiguedad&quot; ## [9] &quot;experiencia&quot; &quot;minoría&quot; &quot;directivo&quot; Solicitamos un diagrama de dispersión En este caso vamos a seleccionar las dos variables (el salario inicial y salario final) y solicitar un diagrama de dispersión. plot(salario_actual~salario_inicial) Como vemos en el diagrama, podemos ver una línea fácilmente. Ello es un buen indicio de que ambas variables están correlacionadas linealmente; sin embargo, es necesario realizar el test estadístico de correlación para poder tener una mirada más fina. Solicitamos el test de correlación Para realizar el test de correlación necesitamos utilizar la función cor.test. Colocamos las variables de interés entre el paréntesis separado por una coma y lo solitiamos. cor.test(salario_actual,salario_inicial) ## ## Pearson&#39;s product-moment correlation ## ## data: salario_actual and salario_inicial ## t = 40.276, df = 472, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.8580696 0.8989267 ## sample estimates: ## cor ## 0.8801175 En este caso hemos solicitado el R de Pearson como el test de correlación. Sin embargo, si la variable no posee una distribución normal sería más adecuado aplicar el Test de Spearman (método no paramétrico). 8.1.2 Cálculo Para calcular un modelo de regresión debemos utilizar la función lm(). Dentro de los paréntesis colocamos las variables de la siguiente manera: variable_dependiente ~ variable_independiente. Al modelo le vamos a llamar modelo1: modelo1=lm(salario_actual~salario_inicial,data=trabajadores) Luego de ello, podemos darnos cuenta que en nuestra sección de objetos (cuadrante superior derecho) ya figura el modelo1. Para solicitar los resultados colocamos la función summary(modelo1) summary(modelo1) ## ## Call: ## lm(formula = salario_actual ~ salario_inicial, data = trabajadores) ## ## Residuals: ## Min 1Q Median 3Q Max ## -35424 -4031 -1154 2584 49293 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.928e+03 8.887e+02 2.17 0.0305 * ## salario_inicial 1.909e+00 4.741e-02 40.28 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 8115 on 472 degrees of freedom ## Multiple R-squared: 0.7746, Adjusted R-squared: 0.7741 ## F-statistic: 1622 on 1 and 472 DF, p-value: &lt; 2.2e-16 Luego de ello seguimos los pasos de nuestro flujograma: Image 8.1.3 Análisis 8.1.3.1 Comprobar si nuestro modelo es válido Para ello, necesitamos ver la tabla ANOVA, vale decir, las últimas líneas de nuestro output del modelo1. Recordemos que estamos realizando una prueba de hipótesis, en la cual nuestras hipótesis son las siguientes: Hipótesis nula (H0) Hipótesis alterna (Ha) El modelo no es válido El modelo es válido Entonces leemos el p-valor. Como en este caso obtuvimos un p valor de &lt;2.2e-16 entonces podemos ver que es menor a 0.05 (alpha), rechazamos la hipótesis nula y concluimos que nuestro modelo es válido. 8.1.3.2 Capacidad explicativa del modelo Para ello, debemos ver el valor del R2 ajustado. En este caso lo interpretamos de la siguiente manera: En este caso, al tener un R2 ajustado de 0.7741 podemos concluir que nuestro modelo explica el 77.41% de la variabilidad de la dependiente (en este caso, salario actual) 8.1.3.3 Verificar si la variable X aporta al modelo El siguiente paso, luego de ver si nuestro modelo es válido y su capacidad explicativa, debemos ver si efectivamente nuestra variable explicativa aporta al modelo. Para ello, debemos visualizar nuestra tabla de coeficientes y analizar la línea que corresponde a la variable de nuestro interés. Hipótesis nula (H0) Hipótesis alterna (Ha) La variable X no aporta al modelo La variable X aporta al modelo En este caso, el pvalor de salario_inicial nos salió &lt;2e-16 ***. Por ello, al ser menor que 0.05, rechazamos nuestra hipótesis nula (la variable no aporta al modelo) y concluimos que efectívamente sí aporta al modelo de regresión lineal simple. Nótese que el pvalor ha venido acompañado de los tres asteriscos o estrellas. Ello indica que el grado de significancia es muy alto. 8.1.3.4 Identificando los coeficientes y construyendo la ecuación Para ello, debemos ver nuevamente la tabla de coeficiente, la línea que corresponde a nuestra variable explicativa. En esta tenemos que prestar atención al número que figura en la columna Estimate. No obstante, siempre sugiero solicitar el siguiente código para así evitar errores en la lectura del coeficiente: modelo1$coefficients ## (Intercept) salario_inicial ## 1928.20576 1.90945 Con este código le hemos dicho al programa que nos muestre los coeficientes del modelo 1. Por ello, al ser una regresión lineal simple, tenemos dos números: el intercepto y el coeficiente del salario inicial. Vemos que el coeficiente del salario inicial es 1.90945, por ello, podemos ver que la relación que existe entre salario inicial y salario actual es directa (al ser positivo el coeficiente). Finalmente, para construir la ecuación utilizamos los coeficientes que hemos obtenido de la siguiente manera: salario_actual = 1928.20576 + (1.90945*salario_inicial) Con esta ecuación del modelo1, dado un valor de salario_inicial, nosotros podemos calcular el salario actual de un trabajador. 8.2 Regresión Lineal Múltiple Te sugiero ver el siguiente tutorial para realizar un modelo de regresión lineal múltiple. 8.2.1 Preparación Solicitamos nuestra base de datos desde la nube library(rio) base_trabajadores=&quot;https://github.com/DataPolitica/salidas/raw/master/Data/trabajadores.sav&quot; trabajadores=import(base_trabajadores) attach(trabajadores) names(trabajadores) ## [1] &quot;id&quot; &quot;sexo&quot; &quot;fechnac&quot; &quot;educ&quot; ## [5] &quot;catlab&quot; &quot;salario_actual&quot; &quot;salario_inicial&quot; &quot;antiguedad&quot; ## [9] &quot;experiencia&quot; &quot;minoría&quot; &quot;directivo&quot; 8.2.2 Cálculo Calculamos un modelo de regresión múltiple en el cual tenemos a salario_actual como dependiente y contamos con tres independiente o explicativas: el salario inicial del trabajador(salario_inicial), los años de educación del trabajador (educ) y los años de antiguedad en el cargo (antiguedad) modelo2=lm(salario_actual~salario_inicial + educ + antiguedad, data=trabajadores) Luego, solicitamos el resultado utilizando la función summary: summary(modelo2) ## ## Call: ## lm(formula = salario_actual ~ salario_inicial + educ + antiguedad, ## data = trabajadores) ## ## Residuals: ## Min 1Q Median 3Q Max ## -30325 -4231 -658 2924 46707 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.999e+04 3.237e+03 -6.175 1.43e-09 *** ## salario_inicial 1.689e+00 5.783e-02 29.209 &lt; 2e-16 *** ## educ 9.661e+02 1.579e+02 6.118 2.00e-09 *** ## antiguedad 1.557e+02 3.506e+01 4.442 1.11e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7646 on 470 degrees of freedom ## Multiple R-squared: 0.8008, Adjusted R-squared: 0.7995 ## F-statistic: 629.7 on 3 and 470 DF, p-value: &lt; 2.2e-16 Una vez tengamos nuestro resultado seguimos nuevamente los pasos de nuestro flujograma: 8.2.3 Análisis 8.2.3.1 Comprobar si nuestro modelo es válido Vemos la tabla ANOVA, vale decir, las últimas líneas de nuestro output del modelo2. Hipótesis nula (H0) Hipótesis alterna (Ha) El modelo no es válido El modelo es válido Entonces leemos el p-valor. Como en este caso obtuvimos un p valor de &lt;2.2e-16 entonces podemos ver que es menor a 0.05 (alpha), rechazamos la hipótesis nula y concluimos que nuestro modelo es válido. 8.2.3.2 Capacidad explicativa del modelo Para ello, debemos ver el valor del R2 ajustado. En este caso lo interpretamos de la siguiente manera: En este caso, al tener un R2 ajustado de 0.7995 podemos concluir que nuestro modelo de regresión múltiple explica el 79.95% de la variabilidad de la dependiente (en este caso, salario actual). 8.2.3.3 Verificar si las variables X´s aporta al modelo Ahora que estamos considerando más de una variable, debemos verificar si efectivamente las tres variables explicativas aportan al modelo. Para ello, debemos visualizar nuevamente nuestra tabla de coeficientes y analizar la línea que corresponde a la variable de nuestro interés. Hipótesis nula (H0) Hipótesis alterna (Ha) La variable X no aporta al modelo La variable X aporta al modelo En este caso, el pvalor de salario_inicial nos salió &lt;2e-16*** ; el de educ salió 2.00e-09*** ; y el de antiguedad salió 1.11e-05***. Por ello, podemos rechazar la hipótesis nula (la variable no aporta al modelo) en los tres casos y concluir que todas las variables aportan al modelo de regresión lineal múltiple. Nótese que todos los p-valor han venido acompañado de los tres asteriscos o estrellas. Ello indica que el grado de significancia es muy alto es las tres variables explicativas. 8.2.3.4 Identificando los coeficientes y construyendo la ecuación Por último, solicitamos los coeficiente de nuestro modelo: modelo2$coefficients ## (Intercept) salario_inicial educ antiguedad ## -19986.50217 1.68916 966.10701 155.70118 Con este código le hemos dicho al programa que nos muestre los coeficientes del modelo 2. En esta ocasión, al ser una regresión lineal múltiple, tenemos cuatro número: el intercepto y el coeficiente del salario_inicial, educ y antiguedad. Sobre los coeficiente podemos ver que: Coeficiente del salario inicial es 1.90945. Es positivo, por ello, podemos ver que la relación es directa (mientras uno aumenta el otro aumenta). Coeficiente de educ es 9.66.10701. Es positivo, la relación es directa. Coeficiente de antiguedad es 155.70118. Es positivo, la relación es directa. Finalmente, para construir la ecuación utilizamos los coeficientes que hemos obtenido de la siguiente manera: salario_actual = -19986.50217 + (1.68916salario_inicial) + (966.10701educ) + (155.70118*antiguedad) Con esta ecuación del modelo2, dado un valor de salario_inicial, años de educación y años de antiguedad, nosotros podemos calcular el salario actual de un trabajador. 8.3 Verificación de supuestos Obtenemos nuestra base de datos library(rio) competitividad=import(&quot;https://github.com/ChristianChiroqueR/banco_de_datos/raw/main/DATA_Peru/COVID%20-%20COMPETITIVIDAD.sav&quot;) names(competitividad) ## [1] &quot;region&quot; &quot;casos&quot; &quot;casos_100k&quot; ## [4] &quot;fallecidos&quot; &quot;poblacion&quot; &quot;altura&quot; ## [7] &quot;pobreza&quot; &quot;vias_pavimentadas&quot; &quot;var1&quot; ## [10] &quot;var2&quot; &quot;var3&quot; &quot;var4&quot; ## [13] &quot;var5&quot; &quot;var6&quot; &quot;var7&quot; ## [16] &quot;var8&quot; &quot;var9&quot; &quot;var10&quot; ## [19] &quot;var11&quot; &quot;var12&quot; &quot;var13&quot; ## [22] &quot;var14&quot; &quot;var15&quot; &quot;var16&quot; ## [25] &quot;var17&quot; &quot;var18&quot; &quot;var19&quot; ## [28] &quot;var20&quot; &quot;var21&quot; &quot;var22&quot; ## [31] &quot;var23&quot; &quot;var24&quot; &quot;var25&quot; ## [34] &quot;var26&quot; &quot;var27&quot; &quot;var28&quot; ## [37] &quot;var29&quot; &quot;var30&quot; &quot;var31&quot; ## [40] &quot;var32&quot; &quot;var33&quot; &quot;var34&quot; ## [43] &quot;var35&quot; &quot;var36&quot; &quot;var37&quot; ## [46] &quot;var38&quot; &quot;var39&quot; &quot;var40&quot; ## [49] &quot;var41&quot; &quot;var42&quot; &quot;var43&quot; ## [52] &quot;var44&quot; &quot;var45&quot; Calculamos un modelo Planteemos un modelo en el que deseamos predecir los casos de Covid-19 por cada 100 mil habitantes en las regiones. Para ello, vamos a utilizar las siguientes variables: Variable dependiente: Casos COVID-19 por cada 100 mil personas Variables independientes: Stock de capital por trabajador (var3) + gasto real por hogar mensual (var5) + morbilidad (var20). modelo1 &lt;- lm(competitividad$casos_100k~ competitividad$var3+competitividad$var5+ competitividad$var20) summary(modelo1) ## ## Call: ## lm(formula = competitividad$casos_100k ~ competitividad$var3 + ## competitividad$var5 + competitividad$var20) ## ## Residuals: ## Min 1Q Median 3Q Max ## -800.31 -360.70 8.18 340.91 1331.92 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.811e+03 1.206e+03 1.501 0.14986 ## competitividad$var3 2.382e-02 8.178e-03 2.913 0.00892 ** ## competitividad$var5 1.484e+00 4.165e-01 3.563 0.00207 ** ## competitividad$var20 -3.678e+01 1.550e+01 -2.373 0.02833 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 548.8 on 19 degrees of freedom ## Multiple R-squared: 0.7314, Adjusted R-squared: 0.689 ## F-statistic: 17.25 on 3 and 19 DF, p-value: 1.185e-05 Una vez calculado nuestro modelo pasamos a la verificaciòn de los supuestos 8.3.1 Linealidad Descrición La linealidad indica que el valor esperado de la variable dependiente es una función lineal de cada variable independiente, manteniendo las demás fijas. La pendiente de esa línea no depende de los valores de las otras variables. Los efectos de diferentes variables independientes sobre el valor esperado de la variable dependiente son aditivos. Cómo detectarlo OPCIÓN 1: Exploración gráfica: Plot de valores residuales frente a valores predichos. OPCIÓN 2: Calculando la correlación bivariada de cada independiente con la dependiente. Código e interpretación plot(modelo1,1) Los puntos deben distribuirse alrededor de una línea horizontal, con una varianza aproximadamente constante. Busque con atención la evidencia de un patrón, lo que indica que el modelo comete errores sistemáticos siempre que hace predicciones inusualmente grandes o pequeñas. Si usamos la correlación, entonces: cor.test(competitividad$casos_100k, competitividad$var3) ## ## Pearson&#39;s product-moment correlation ## ## data: competitividad$casos_100k and competitividad$var3 ## t = 4.3943, df = 21, p-value = 0.0002531 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.3916650 0.8592019 ## sample estimates: ## cor ## 0.6921267 cor.test(competitividad$casos_100k, competitividad$var5) ## ## Pearson&#39;s product-moment correlation ## ## data: competitividad$casos_100k and competitividad$var5 ## t = 4.1847, df = 21, p-value = 0.0004178 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.3630301 0.8502056 ## sample estimates: ## cor ## 0.674325 cor.test(competitividad$casos_100k, competitividad$var20) ## ## Pearson&#39;s product-moment correlation ## ## data: competitividad$casos_100k and competitividad$var20 ## t = -2.3995, df = 21, p-value = 0.02578 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.7354473 -0.0638803 ## sample estimates: ## cor ## -0.4638681 también lo puedes graficar para que te de una idea de forma más rápida: #install.packages(&quot;corrplot&quot;) library(corrplot) ## corrplot 0.84 loaded #La funci?n cor calcula la matriz de correlaciones M&lt;-cor(competitividad[,c(3,11,13,28)],method=&quot;pearson&quot;) corrplot(M, method=&quot;circle&quot;,type=&quot;upper&quot;) corrplot(M, method=&quot;number&quot;) corrplot.mixed(M) 8.3.2 Normalidad de residuos Descrición Identificar si los errores siguen una distribución normal. Cómo detectarlo Exploración gráfica: QQ plot de residuos Pruebas de normalidad a los residuos. Normalmente bastaría con la prueba de Shapiro Wilk, pero también se pueden probar otros como Lillieford, Kolmogorov (no es muy exigente), entre otros. Código e interpretación Si usamos sólo gráfico plot(modelo1, 2) Todos los puntos deben estar sobre la diagonal. Si usamos prueba de normalidad shapiro.test(modelo1$resid) ## ## Shapiro-Wilk normality test ## ## data: modelo1$resid ## W = 0.96627, p-value = 0.6006 H0: Es normal | Ha: No es normal Si el pvalor es menor a 0.05 entonces no existe normalidad de residuos (problema!). 8.3.3 Homocedasticidad Descrición La homocedasticidad indica que las variancias de los errores son constantes. Cuando no se cumple es un problema porque los estimadores no son consistentes ni eficientes. Cómo detectarlo OPCIÓN 1: Exploración gráfica: diagrama de residuos standarizados y valores predichos. OPCIÓN 2: Con el Score Test for Non-Constant Error Variance, también llamado Test Breusch Pagan. Evalúa si la varianza del error cambia con el nivel de la variable respuesta (valores ajustados) o con una combinación lineal de predictores. Código e interpretación Si usamos el gráfico plot(modelo1, 3) En el Gráfico la línea roja debe seguir una tendencia horizontal. Si usamos el BP: library(lmtest) bptest(modelo1) ## ## studentized Breusch-Pagan test ## ## data: modelo1 ## BP = 1.6987, df = 3, p-value = 0.6372 H0: El modelo es homocedástico Ha: El modelo es heterocedástico Si el pvalor es menor a 0.05 entonces el modelo es heterocedástico (problema!). 8.3.4 Ausencia de multicolinealidad Descripción Se aplica en la regresión lineal MÚLTIPLE. Significa que las variables explicativas están relacionadas linealmente entre sí. La multicolinealidad hace que los coeficientes del modelo se vuelvan inestables, es decir, oscilarán violentamente ante cambios mínimos en las variables de insumo. Cómo detectarlo Con el Factor de Inflación de Varianza (VIF). Código e interpretación library(DescTools) VIF(modelo1) ## competitividad$var3 competitividad$var5 competitividad$var20 ## 1.337011 1.231735 1.098254 Valores &gt; 5 indican presencia de multicolinealidad. 8.3.5 Independencia de residuos Descripción Si los errores residuales no son independientes, es probable que demuestren algún tipo de patrón (que no siempre es obvio a simple vista). Cómo detectarlo Se puede realizar el Test de Durbin Watson (que mide el grado de correlación de cada error residual con el error residual anterior) Código e interpretación #Default library(car) durbinWatsonTest(modelo1) ## lag Autocorrelation D-W Statistic p-value ## 1 -0.04132242 1.743747 0.492 ## Alternative hypothesis: rho != 0 Durbin Watson: Las hipótesis son: H0: Los residuos son independientes Ha: Los residuos no son independientes Si el pvalor es menor a 0.05 entonces los residuos no son independientes o también se podría decir que están autocorrelacionados (problema!) "]]
